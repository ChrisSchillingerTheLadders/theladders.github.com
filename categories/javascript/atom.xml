<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: JavaScript | TheLadders Engineering Stories]]></title>
  <link href="http://dev.theladders.com/categories/javascript/atom.xml" rel="self"/>
  <link href="http://dev.theladders.com/"/>
  <updated>2015-04-27T12:07:06-04:00</updated>
  <id>http://dev.theladders.com/</id>
  <author>
    <name><![CDATA[TheLadders Engineering]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[CasperJS the Friendly Testing Framework]]></title>
    <link href="http://dev.theladders.com/2015/03/casperjs-the-friendly-testing-framework/"/>
    <updated>2015-03-25T16:30:00-04:00</updated>
    <id>http://dev.theladders.com/2015/03/casperjs-the-friendly-testing-framework</id>
    <content type="html"><![CDATA[<p><blockquote><p>If you don&rsquo;t like testing your product, most likely your customers won&rsquo;t like to test it either.</p><footer><strong>&mdash; Anonymous</strong></footer></blockquote></p>

<p>When we started our new <a href="https://www.theladders.com/careers/search">job market guide</a>
project (a site where career-minded professionals can check out open positions
and stats such as average compensation), the question of testing came up pretty
quickly. We had used <a href="http://jasmine.github.io/">Jasmine</a> for
JavaScript unit testing on a previous project so we kept using it, but it wasn&rsquo;t enough.
Our Jasmine tests could pass, but the site might not actually work. We needed
end-to-end tests.</p>

<p>One of the new tools we found was <a href="http://casperjs.org/">CasperJS</a>. It&rsquo;s a neat
JavaScript project that uses <a href="http://phantomjs.org/">PhantomJS</a> to open a headless
browser, go to your site, take some actions and then make assertions. We&rsquo;re using
CasperJS for end-to-end testing and we&rsquo;re automating the test runs with
<a href="http://gruntjs.com/">Grunt</a>.</p>

<p>Here&rsquo;s a snippet of a test for our &lsquo;share&rsquo; feature:
``` javascript
function emailCaptureTopFormTest() {</p>

<pre><code>casper.then(givenCareersPage);
casper.then(whenEmailFormIsFilledOut);
casper.then(thenConfirmationIsShown);
</code></pre>

<p>}</p>

<p>function givenCareersPage() {</p>

<pre><code>casper.open(DOMAIN + 'careers/NY/sales/1');
</code></pre>

<p>}</p>

<p>function whenEmailFormIsFilledOut() {</p>

<pre><code>casper.click('[data-js="email-capture__top-link-test"]');
casper.sendKeys(topFormInputSelector, 'jblocktest' + new Date().getTime() + '@theladders.net');
casper.click('[data-js="email-capture__top-submit"]');
</code></pre>

<p>}</p>

<p>function thenConfirmationIsShown() {</p>

<pre><code>casper.waituntilVisible('[data-js="email-capture__confirmation"]',
        util.success("email confirmation ok"),
        util.failWithScreenshot("email-confirmation-fail",
                                "email confirmation didn't appear",
                                SCREENSHOT_OPTIONS));
</code></pre>

<p>}
```</p>

<p>The test opens up the page, fills out the form, and makes sure the confirmation
window appears. If it doesn&rsquo;t appear, the test takes a screenshot and reports a failure.</p>

<p>The tests are generally pretty fast. We use Grunt to kick off the test suites
so that all you need to do to run them is type <code>grunt test</code>. (That&rsquo;s a lot
easier to remember than <code>casperjs --ssl-protocol=any --ignore-ssl-errors=true
test path/to/tests</code>!) Simpler tests are typically less than a second to run,
but there are a few slower tests that rely on external services, which can
take as long as 15 seconds to run. This led to concerns about the test run
time. We want to run the whole suite of tests frequently, but we don&rsquo;t want it
to take a couple of minutes each time.</p>

<p>The solution I went with was running them in parallel. They&rsquo;re all independent
so there&rsquo;s no need for any test to wait for any other test to finish. CasperJS
doesn&rsquo;t officially support parallelization so I jury-rigged something together
with a shell script. It gets each test file, runs them all as background processes
and redirects their output to temporary files. Once that&rsquo;s done, it cats all the
output in order and then uses <code>grep</code> to print failures at the end.</p>

<p>Here&rsquo;s some sample output after the test suite has run:
```text
Test file: /casper/tests/no_search_results_test.js</p>

<h1>search no results test</h1>

<p>PASS no-jobs-search-ok: Saw no jobs container
PASS 1 test executed in 2.227s, 1 passed, 0 failed, 0 dubious, 0 skipped.</p>

<p>Done, without errors.</p>

<hr />

<p>FAIL PremiumSignupTestfail:  Expected pricing form. Didn&rsquo;t see it.</p>

<h1>file: /casper/tests/premium_signup_test.js</h1>

<p>FAIL 1 test executed in 13.195s, 0 passed, 1 failed, 0 dubious, 0 skipped.</p>

<p>real    0m25.646s
user    1m16.980s
sys 0m7.416s
^ Time it took for this task.
```</p>

<p>I used the <code>time</code> command to print out how long the suite takes. It&rsquo;s now
around 25s instead of 90s+. That is, the run time is the slowest test&rsquo;s run
time plus some overhead. That&rsquo;s a big improvement over the sum of all the tests'
 run times!</p>

<p>This was great when we only had a few tests, but as the suite grew larger, I
noticed the server was starting to struggle. It could handle five connections
 opening at once, but a hundred was causing tests to time out. My solution for
this was to split the tests into smaller batches. Instead of running 100 tests
all at once and bringing the server down, I can run two sets of 50. It&rsquo;s a
little slower than it would be if they could all run at once, but it&rsquo;s definitely
faster than having some tests randomly time out and fail.</p>

<p>Now that the casper tests are quick and easy to run, they&rsquo;re being used more
frequently and catching errors faster. Some developers are writing casper tests
before they write the actual code, too.</p>

<p>While CasperJS is a great tool for testing interactions and catching errors (like
forms not submitting correctly), it doesn&rsquo;t particularly care about how the page
looks. The casper tests will happily pass even if no CSS loads on the page. A
human would obviously see something is broke, but the casper tests won&rsquo;t. We
wanted to be able to catch problems like that without manually looking at
every page. Fortunately, there&rsquo;s a tool for that:
<a href="https://github.com/Huddle/PhantomCSS">PhantomCSS</a>.</p>

<p>PhantomCSS builds on top of CasperJS. It takes screenshots of your
site and then after you&rsquo;ve done work, it takes new screenshots. It then compares
the two and highlights any changes. This can be incredibly useful. For example,
suppose you&rsquo;re changing the header on one pager to be centered. If this accidentally
center headers on other pages, that will show up as a failure in PhantomCSS.</p>

<p>Since PhantomCSS tests run the same way as the casper tests, I was able to use the
same method to run them in parallel. Like with casper tests, individually they&rsquo;re
pretty quick, but running them all sequentially can be slow. Running them in
parallel is a big time saver.</p>

<p>Now that we are using CasperJS and PhantomJS, our confidence when releasing has
gone way up. We no longer need to manually check styles on every page because
PhantomCSS will show us every change. We donâ€™t need to click through flows because
CasperJS does that for us. We&rsquo;ve been releasing new bug-free features at a consistent
rate that wouldn&rsquo;t be possible if we were still manually testing.</p>
]]></content>
  </entry>
  
</feed>
