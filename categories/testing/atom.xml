<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Testing | TheLadders Engineering Stories]]></title>
  <link href="http://dev.theladders.com/categories/testing/atom.xml" rel="self"/>
  <link href="http://dev.theladders.com/"/>
  <updated>2015-03-25T15:57:28-04:00</updated>
  <id>http://dev.theladders.com/</id>
  <author>
    <name><![CDATA[TheLadders Engineering]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[CasperJS the Friendly Testing Framework]]></title>
    <link href="http://dev.theladders.com/2015/03/casperjs-the-friendly-testing-framework/"/>
    <updated>2015-03-25T16:30:00-04:00</updated>
    <id>http://dev.theladders.com/2015/03/casperjs-the-friendly-testing-framework</id>
    <content type="html"><![CDATA[<p><blockquote><p>If you don&rsquo;t like testing your product, most likely your customers won&rsquo;t like to test it either.</p><footer><strong>&mdash; Anonymous</strong></footer></blockquote></p>

<p>When we started our new <a href="https://www.theladders.com/careers/search">job market guide</a>
project (a site where career-minded professionals can check out open positions
and stats such as average compensation), the question of testing came up pretty
quickly. We had used <a href="http://jasmine.github.io/">Jasmine</a> for
JavaScript unit testing on a previous project so we kept using it, but it wasn&rsquo;t enough.
Our Jasmine tests could pass, but the site might not actually work. We needed
end-to-end tests.</p>

<p>One of the new tools we found was <a href="http://casperjs.org/">CasperJS</a>. It&rsquo;s a neat
JavaScript project that uses <a href="http://phantomjs.org/">PhantomJS</a> to open a headless
browser, go to your site, take some actions and then make assertions. We&rsquo;re using
CasperJS for end-to-end testing and we&rsquo;re automating the test runs with
<a href="http://gruntjs.com/">Grunt</a>.</p>

<p>Here&rsquo;s a snippet of a test for our &lsquo;share&rsquo; feature:
``` javascript
function emailCaptureTopFormTest() {</p>

<pre><code>casper.then(givenCareersPage);
casper.then(whenEmailFormIsFilledOut);
casper.then(thenConfirmationIsShow);
</code></pre>

<p>}</p>

<p>function givenCareersPage() {</p>

<pre><code>casper.open(DOMAIN + 'careers/NY/sales/1');
</code></pre>

<p>}</p>

<p>function whenEmailFormIsFilledOut() {</p>

<pre><code>casper.click('[data-js="email-capture__top-link-test"]');
casper.sendKeys(topFormInputSelector, 'jblocktest' + new Date().getTime() + '@theladders.net');
casper.click('[data-js="email-capture__top-submit"]');
</code></pre>

<p>}</p>

<p>function thenConfirmationIsShown() {</p>

<pre><code>casper.waituntilVisible('[data-js="email-capture__confirmation"]', 
        util.success("email confirmation ok"),
        util.failWithScreenshot("email-confirmation-fail", 
                                "email confirmation didn't appear", 
                                SCREENSHOT_OPTIONS));
</code></pre>

<p>}
```</p>

<p>The test opens up the page, fills out the form, and makes sure the confirmation
window appears. If it doesn&rsquo;t appear, the test takes a screenshot and reports a failure.</p>

<p>The tests are generally pretty fast. We use Grunt to kick off the test suites
so that all you need to do to run them is type <code>grunt test</code>. (That&rsquo;s a lot
easier to remember than <code>casperjs --ssl-protocol=any --ignore-ssl-errors=true
test path/to/tests</code>!) Simpler tests are typically less than a second to run,
but there are a few slower tests that rely on external services, which can
take as long as 15 seconds to run. This led to concerns about the test run
time. We want to run the whole suite of tests frequently, but we don&rsquo;t want it
to take a couple of minutes each time.</p>

<p>The solution I went with was running them in parallel. They&rsquo;re all independent
so there&rsquo;s no need for any test to wait for any other test to finish. CasperJS
doesn&rsquo;t officially support parallelization so I jury-riggered something together
with a shell script. It gets each test file, runs them all as background processes
and redirects their output to temporary files. Once that&rsquo;s done, it cats all the
output in order and then uses <code>grep</code> to print failures at the end.</p>

<p>Here&rsquo;s some sample output after the test suite has run:
```text
Test file: /casper/tests/no_search_results_test.js</p>

<h1>search no results test</h1>

<p>PASS no-jobs-search-ok: Saw no jobs container
PASS 1 test executed in 2.227s, 1 passed, 0 failed, 0 dubious, 0 skipped.</p>

<p>Done, without errors.</p>

<hr />

<p>FAIL PremiumSignupTestfail:  Expected pricing form. Didn&rsquo;t see it.</p>

<h1>file: /casper/tests/premium_signup_test.js</h1>

<p>FAIL 1 test executed in 13.195s, 0 passed, 1 failed, 0 dubious, 0 skipped.</p>

<p>real    0m25.646s
user    1m16.980s
sys 0m7.416s
^ Time it took for this task.
```</p>

<p>I used the <code>time</code> command to print out how long the suite takes. It&rsquo;s now
around 25s instead of 90s+. That is, the run time is the slowest test&rsquo;s run
time plus some overhead. That&rsquo;s a big improvement over the sum of all the tests'
 run times!</p>

<p>This was great when we only had a few tests, but as the suite grew larger, I
noticed the server was starting to struggle. It could handle five connections
 opening at once, but a hundred was causing tests to time out. My solution for
this was to split the tests into smaller batches. Instead of running 100 tests
all at once and bringing the server down, I can run two sets of 50. It&rsquo;s a
little slower than it would be if they could all run at once, but it&rsquo;s definitely
faster than having some tests randomly time out and fail.</p>

<p>Now that the casper tests are quick and easy to run, they&rsquo;re being used more
frequently and catching errors faster. Some developers are writing casper tests
before they write the actual code, too.</p>

<p>While CasperJS is a great tool for testing interactions and catching errors (like
forms not submitting correctly), it doesn&rsquo;t particularly care about how the page
looks. The casper tests will happily pass even if no CSS loads on the page. A
human would obviously see something is broke, but the casper tests won&rsquo;t. We
wanted to be able to catch problems like that without manually looking at
every page. Fortunately, there&rsquo;s a tool for that:
<a href="https://github.com/Huddle/PhantomCSS">PhantomCSS</a>.</p>

<p>PhantomCSS builds on top of CasperJS. It takes screenshots of your
site and then after you&rsquo;ve done work, it takes new screenshots. It then compares
the two and highlights any changes. This can be incredibly useful. For example,
suppose you&rsquo;re changing the header on one pager to be centered. If this accidentally
center headers on other pages, that will show up as a failure in PhantomCSS.</p>

<p>Since PhantomCSS tests run the same way as the casper tests, I was able to use the
same method to run them in parallel. Like with casper tests, individually they&rsquo;re
pretty quick, but running them all sequentially can be slow. Running them in
parallel is a big time saver.</p>

<p>Now that we are using CasperJS and PhantomJS, our confidence when releasing has
gone way up. We no longer need to manually check styles on every page because
PhantomCSS will show us every change. We don’t need to click through flows because
CasperJS does that for us. We&rsquo;ve been releasing new bug-free features at a consistent
rate that wouldn&rsquo;t be possible if we were still manually testing.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mutation testing with PIT: A step beyond normal code coverage]]></title>
    <link href="http://dev.theladders.com/2013/02/mutation-testing-with-pit-a-step-beyond-normal-code-coverage/"/>
    <updated>2013-02-20T03:15:15-05:00</updated>
    <id>http://dev.theladders.com/2013/02/mutation-testing-with-pit-a-step-beyond-normal-code-coverage</id>
    <content type="html"><![CDATA[<p><blockquote><p>&ldquo;Program testing can be used to show the presence of bugs, but never to show their absence!&rdquo;</p><footer><strong>&mdash;Edsger W. Dijkstra</strong></footer></blockquote></p>

<p>When we started out building our <a href="http://www.cenedella.com/job-search/job-offer-guaranteed-signature/">Signature program</a>, we had a goal in mind &ndash; test the &lt;insert expletive of choice here&gt; out of it.  We also wanted to make sure that not only did we test it, but we tested it right.  Regular code line coverage tools like <a href="http://www.atlassian.com/software/clover/overview">Clover</a> are great, but typically only tell you that a line of code was executed &ndash; not necessarily that it was verified.  Many developers often see them as a way to determine what&rsquo;s been tested, but in reality they are better at<em> highlighting code that hasn&rsquo;t been tested at all</em>.</p>

<p>Our interest in mutation testing stemmed from a talk about how occasionally we see bad/ineffective tests, ones that give the impression of testing the code but in reality don&rsquo;t do a great job.  <a href="https://twitter.com/SeanTAllen">Sean T Allen</a> and I had apparently both already been looking into a new tool, because once the discussion came up we were already on the same page.  Enter <a href="http://pitest.org/">PIT</a>, a mutation testing tool under active development.  We decided to try it out in combination with Clover, and the results were:</p>

<p><img class="center" src="/images/tim_and_eric_mind_blown.gif" title="&lsquo;Tim and Eric Mind Blown gif&rsquo;)" ></p>

<h1></h1>

<h1>But first, what is mutation testing?</h1>

<p>For those unfamiliar with how mutation testing works, I&rsquo;ll offer a brief summary.  After your sources and tests are compiled and run, a mutation test framework like PIT will alter the program code and insert ‘mutations’, such as changing != to == or completely removing a line.  It will then run the tests that exercise that chunk of code again, with the expectation that at least one of them should now fail.  If your tests are well written, or more importantly, <em>complete</em>, then at least one assertion should have been broken by PIT’s change.  (For more, <a href="http://www.simple-talk.com/dotnet/.net-tools/mutation-testing/">Jeremy Jarrell’s introduction</a> (first 2 sections) sums it up pretty well)</p>

<h1></h1>

<h1>Your 100% coverage?  It’s a lie.</h1>

<p>You write a test &ndash; it&rsquo;s green and all is well.  But are you <em>certain</em> that it will fail if someone mistakenly alters the code?  “Yea, I have tons-o-coverage” you say?  Typical line coverage tools like Clover can lull you into a false sense of security by showing 100% coverage without really delivering on that promise.  And that’s probably fine &ndash; heck, a lot of teams/projects would be happy to break 90% overall line coverage (or 50%&hellip;or 20%).  But there are a few of us here that border on insane and try to push the envelope &ndash; more, more, more!</p>

<h1>So what&rsquo;s so great/different about mutation testing?</h1>

<h2>Testing your tests:</h2>

<p>One of the most important long-term benefits of a test is not knowing that it passes, but rather knowing that it will fail if the code is broken.  When not TDDing, I tend to alter the code or comment out blocks and ensure that the test fails as expected.  Sometimes we write tests that don&rsquo;t fail correctly with the code they test: maybe because of a mistaken assumption, or maybe because of a slight oversight &ndash; it happens.  Mutation testing is an effective, automated way of enforcing that tests fail correctly.</p>

<h2>Code is verified:</h2>

<p>PIT provides a way of ensuring that you&rsquo;ve written complete tests that verify the results of executing a piece of code.  The core concept of mutation testing is a powerful one &ndash; if you botch a line of code, a test should break somewhere.  If a test doesn&rsquo;t break, it means your tests aren&rsquo;t complete, the test may be wrong, or the line of code just flat out isn&rsquo;t doing anything.  In one case, we discovered dead code that was identified by PIT when switching our storage model.</p>

<p>Depending on how far you believe in test coverage in general and mutation testing itself, it can be a great ally.  We decided to aim high &ndash; test everything.  PIT was vital in ensuring that we were actually verifying each line of code that we set out to.</p>

<h1></h1>

<h1>An Example:</h1>

<p>To illustrate an example of what PIT does, consider the below (very basic) class and test:</p>

<p>``` java PersonFactory <a href="https://github.com/TheLadders/pit-example/blob/master/src/main/java/com/theladders/PersonFactory.java">https://github.com/TheLadders/pit-example/blob/master/src/main/java/com/theladders/PersonFactory.java</a> Source
public class PersonFactory
{
  public Person createPerson()
  {</p>

<pre><code>Person person = new Person();
person.setFirstName("First");
person.setLastName("Last");
return person;
</code></pre>

<p>  }
}
<code>
</code> java Person <a href="https://github.com/TheLadders/pit-example/blob/master/src/main/java/com/theladders/Person.java">https://github.com/TheLadders/pit-example/blob/master/src/main/java/com/theladders/Person.java</a> Source
public class Person
{
  private String firstName;
  private String lastName;</p>

<p>  public String getFirstName()
  {</p>

<pre><code>return firstName;
</code></pre>

<p>  }</p>

<p>  public void setFirstName(String firstName)
  {</p>

<pre><code>this.firstName = firstName;
</code></pre>

<p>  }</p>

<p>  public String getLastName()
  {</p>

<pre><code>return lastName;
</code></pre>

<p>  }</p>

<p>  public void setLastName(String lastName)
  {</p>

<pre><code>this.lastName = lastName;
</code></pre>

<p>  }
}
<code>
</code> java PersonFactoryTest <a href="https://github.com/TheLadders/pit-example/blob/master/src/test/java/com/theladders/PersonFactoryTest.java">https://github.com/TheLadders/pit-example/blob/master/src/test/java/com/theladders/PersonFactoryTest.java</a> Source
public class PersonFactoryTest
{
  @Test
  public void test()
  {</p>

<pre><code>Person person = new PersonFactory().createPerson();
String firstName = person.getFirstName();
String lastName = person.getLastName();
assertEquals("First", firstName);
// forgot test for last name
</code></pre>

<p>  }
}
```</p>

<p>Clover (and PIT) will say that the <em><strong>line</strong></em> coverage is 100%.  But at a close glance &ndash; how many untested pieces of code do you see?  PIT <em><strong>mutation</strong></em> coverage will point out that there are 2 &ndash; the call to person.setLastName(&ldquo;Last&rdquo;) and the getLastName() method.  Both were executed as part of the test, but neither are actually verified for correctness.</p>

<h2>Clover Results:</h2>

<h2><img src="/images/clover.png" alt="clover results" /></h2>

<h2>PIT Results:</h2>

<h2><img src="/images/pit-failure.png" alt="pit failure" /></h2>

<h2><img src="/images/person-factory.png" alt="PersonFactory class" /></h2>

<p>(Person report excluded for brevity)</p>

<p>You’ll notice that the setLastName method in the PersonFactory is highlighted in red, with an explanation below:
removed call to com/theladders/Person::setLastName : SURVIVED</p>

<p>What this means is that PIT altered the code and removed the call to setLastName() completely, ran the tests again, and they all still passed &ndash; meaning that the mutation survived.  You’ll also notice that it tried the same thing for setFirstName(), but it was successfully killed by our test (it failed, as it should).</p>

<p>Once we add a test for last name, we’ll see that PIT will now report that all mutations are killed.  Essentially what it means, is that PIT couldn’t find a way to screw with the code without breaking a test.</p>

<p>``` java PersonFactoryTest <a href="https://github.com/TheLadders/pit-example/blob/master/src/test/java/com/theladders/PersonFactoryTest.java">https://github.com/TheLadders/pit-example/blob/master/src/test/java/com/theladders/PersonFactoryTest.java</a> Source
public class PersonFactoryTest
{
  @Test
  public void test()
  {</p>

<pre><code>Person person = new PersonFactory().createPerson();
String firstName = person.getFirstName();
String lastName = person.getLastName();
assertEquals("First", firstName);
assertEquals("Last", lastName);
</code></pre>

<p>  }
}
```</p>

<h2>PIT Results afterwards:</h2>

<h2><img src="/images/pit-success.png" alt="Pit success" /></h2>

<p>This was a very trivial example, and PIT supports much more than what I&rsquo;ve shown you here.  As you may have noticed, I skipped over one of the killed mutations: if (x != null) null else throw new RuntimeException.  This is another type of fault that PIT will try to introduce for return objects.  The full list of mutations can be found <a href="http://pitest.org/quickstart/mutators/">here</a>.</p>

<h1></h1>

<h1>Our Experience with PIT:</h1>

<p>We started using it last year on a new project with some really great success.  As part of it, we were building a RESTful web service with Jersey.  It was a green field project with no legacy code &ndash; everything written from scratch except for small internal libraries.  We tested almost every meaningful thing we could about the server (web interfaces, security XML configs, null validation rules, etc).  It was very heavy on integration tests &ndash; some just verified all the business components working together and some deployed the server on embedded Jetty and hit the web endpoints.  Towards the end we were maintaining around 98% in both Clover and PIT (excluding Data Transfer Object classes), and ended up around 95%.</p>

<p>While we also used Clover for basic code coverage, as we got our PIT mutation coverage up into the 90s I stopped paying much attention to Clover.  Our use of PIT was to ensure that we were actually testing and verifying all the parts of the code that we thought we were, and to find the places where we needed to fill in more tests or assertions.  We would add/modify tests so that each line of code we wrote (almost) was also backed by an assertion somewhere.  Essentially, &ldquo;Hey PIT, where do I need to add more tests and assertions?&rdquo;</p>

<p>This gave us extreme confidence in our tests &ndash; if the code was modified incorrectly (with some small exceptions), a test would break and we knew it.  The effects of that confidence were outstanding.  At TheLadders we place a lot of value in code quality and &ldquo;doing things right,&rdquo; so refactoring is a large part of our process.  It enabled us to refactor at will with little fear of breaking anything, which happened quite frequently in many different ways, especially as a new project growing from the ground up.</p>

<p>The best example of a big win was a refactoring to shift how we stored and tracked state.  When we first started out, we were creating and updating rows in the database (update in place).  We decided to switch to an <a href="http://martinfowler.com/eaaDev/EventSourcing.html">Event Sourcing</a> approach &ndash; instead of storing/retrieving state in the database, we instead stored &lsquo;actions&rsquo; and inputs in the database and then rebuilt the state in memory from those actions.  This was a large change to how a lot of the internals operated, and would normally carry a big risk factor in breaking existing functionality.  In this case, that risk factor was minimal and hardly played a part in our decision.  Because of the confidence we had in our tests thanks to PIT (and the fact that the majority of them were high level integration tests), all we did was start switching over and making changes until the tests were green again, and we were done.  The tests were the ultimate source of how the server needed to act, and PIT helped ensure that those tests covered everything the server was expected to do.</p>

<p>If you want to try it out yourself, the above example in code is available here: <a href="https://github.com/TheLadders/pit-example">https://github.com/TheLadders/pit-example</a></p>

<p>Join the discussion over at <a href="http://www.reddit.com/r/programming/comments/18w2ia/who_tests_the_tests_mutation_testing_with_pit/">reddit</a>.</p>
]]></content>
  </entry>
  
</feed>
